export const experiences = [
  {
    role: 'Cloud Platform developer',
    company: 'Grainger',
    period: '2024 - present',
    description: 'Multicloud management using Terraform (AWS, Azure, GCP), Implementing CI/CD pipelines using GitHub Actions and Terraform for infrastructure as code. FinOps and Cost Optimization using CloudZero. Development of agentic AI applications with Cloud Zdero MCP integration to send exedcutive reports about cloud costs and usage.'
  },
  {
    role: 'Infrastructure Engineer Lead',
    company: 'Whirlpool',
    period: '2024 - 2025',
    description: 'Preparing landing zone and setting up GCP infrastructure using Terraform, Implementing CI/CD pipelines using GitHub Actions and Terraform for infrastructure as code.'
  },
  {
    role: 'Cloud Engineer',
    company: 'P&G',
    period: '2023 - 2024',
    description: 'Migrating HR Systenm App to GCP Cloud Run microservices, Implementing CI/CD pipelines using GitHub Actions and Terraform for infrastructure as code.'
  },
  {
    role: 'Development Team Lead',
    company: 'Autozone',
    period: '2023 - 2023',
    description: 'Led the development team for Autozone Search e-commerce platform, Implementing new features and optimizing performance.'
  },
  {
    role: 'Senior Cloud Engineer',
    company: 'Equifax',
    period: '2022 - 2023',
    description: 'Led the design and implementation of a multi-cloud strategy, improving redundancy and reducing vendor lock-in. Automated infrastructure provisioning using Terraform and Ansible, which decreased manual effort by 90%.'
  },
  {
    role: 'Cloud DevOps Engineer',
    company: 'Cigna',
    period: '2020 - 2022',
    description: 'Managed Kubernetes clusters on GCP, ensuring high availability and scalability for critical applications. Developed and maintained CI/CD pipelines using GitLab CI, which improved deployment frequency by 4x.'
  },
  {
    role: 'Big Data Developer',
    company: 'EPAM Systems',
    period: '2018 - 2020',
    description: 'Built and optimized data processing jobs using Apache Spark and Hadoop. Designed and managed data workflows with Airflow, processing terabytes of data daily.'
  },
  {
    role: 'Software Engineer',
    company: 'Telefonica',
    period: '2016 - 2018',
    description: 'Developed and maintained backend services using Python and Django. Contributed to the development of a large-scale data warehousing solution.'
  }
];